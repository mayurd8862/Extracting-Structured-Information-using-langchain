# Extracting Structured Information using Langchain

## üéØ  Objective
This project aims to extract structured details about characters from stories in a provided dataset and output the required details in JSON format. The script leverages embeddings for information retrieval and processing using MistralAI with LangChain. The goal is to transform unstructured narrative data into a structured format using embeddings and processing techniques. 

---

## ü§ñ Tech Stack used:
- **python**
- **Groq** - A specialized AI accelerator designed for large language models, offering high performance and efficiency. used "llama3" LLM model through groq.
- **Langchain** - used for documents loader, llm integration
- **Langsmith** - Monitoring and visualizing LLM calls, tokens, and other LLM parameters
- **git** - for version control system
- **Streamlit** - For user interface creation "IN PROGRESS"
  
## üõ†Ô∏è Installation 

1. Clone the Repository:
    ```bash
    git clone https://github.com/mayurd8862/Extracting-Structured-Information-using-langchain.git
    ```
2. Navigate to the project directory:
    ```bash
    cd Extracting-Structured-Information-using-langchain
    ```
    
3. Create a virtual environment and activate it:
    ```bash
    python -m venv venv
    venv\Scripts\activate
    ```

4. Install Dependencies:
    ```bash
    pip install -r requirements.txt
    ```
    
## üîê Setup API keys

- Create a .env file in the root directory of the project and add following api keys to it.
  
  ```bash
   LANGCHAIN_API_KEY = your_langchain_api_key
   GROQ_API_KEY = your_groq_api_key
   ```
  
## üöÄ Usage

1. **üîç Compute Embeddings :**
Run the following file to compute embeddings  for all story files and persist the data into the vector database:

```bash
python compute_embeddings.py 
```

![image](https://github.com/user-attachments/assets/651454fe-4af4-4ca4-9c8a-86b26a719d47)


2. **üïµÔ∏è Get Character Information :**
Run the following file and provide character as a input to retrieve structured details about a character:

```bash
python get_character_info.py 
```
![image](https://github.com/user-attachments/assets/810830d2-732a-4fd8-901b-22d430b63128)


## ‚úÖ Output Result

To get character information, run the following command:
```bash
python get_character_info.py 
```

After running the above command, you will be prompted to enter the character name:
```bash
Enter the character you want to search: eliza
```

Upon entering the character name, the script will save the character's information as a JSON file in the current directory.

![image](https://github.com/user-attachments/assets/6687eaeb-b6dd-4fc5-8205-9e3ffc421322)




---


## üëÄ Monitoring LLM calls with LangSmith

LangSmith is a powerful platform designed to provide comprehensive visibility and control over your Large Language Model (LLM) calls within your agents.

1. **Login to LangSmith**: Visit the LangSmith website and enter your credentials to log in to your account.
2. **Go to Projects**: Once logged in, navigate to the "Projects" section of the LangSmith dashboard.
Locate the project(s) that you have integrated with LangSmith. You can identify them by their names or descriptions.
3. **Monitor LLM Call Flows**: Click on a specific project to view its details. Go to the Runs section and analyse llm calls and outputs
4. **visualize**: In the "Monitoring" section, you should see a visualization of the LLM call flows within that project.
The visualization will display the sequence of LLM calls, their relationships, and any dependencies between them.



![image](https://github.com/user-attachments/assets/9aa59e03-196e-4abf-b57c-0d08e237fe43)


## üìß Contact 
For any questions or suggestions, feel free to reach out:

- **Email**: mayur.dabade21@vit.edu
- **GitHub** : [mayurd8862](https://github.com/mayur8862)
- **LinkedIn** : [https://www.linkedin.com/in/mayur-dabade-b527a9230](https://www.linkedin.com/in/mayur-dabade-b527a9230)













